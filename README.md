# ğŸŒ Global Event Pipeline

An end-to-end ETL pipeline that fetches global news events from APIs, processes them, and stores them in MongoDB.  
Built with **Docker**, orchestrated with **docker-compose**, scheduled using **cron**, and fully automated with **GitHub Actions CI/CD** to DockerHub.

---

## ğŸš€ Features

- **ETL Automation**: Fetches events from the News API and stores in MongoDB.
- **Scheduled Runs**: Weekly cron job triggers ETL automatically.
- **Containerized Deployment**: All components run inside Docker containers.
- **Continuous Integration (CI)**: Automatically builds and tests on every push.
- **Continuous Deployment (CD)**: Automatically pushes Docker image to DockerHub.
- **Log Management**: Automated log rotation.

---

## ğŸ›  Tech Stack
- **Python** (FastAPI, Requests, PyMongo, NLTK, PyYAML)
- **MongoDB** (Data Storage)
- **Docker & docker-compose**
- **GitHub Actions** (CI/CD)
- **Cron** (Scheduling)

---

## ğŸ“‚ Project Structure

```
global-event-pipeline/
â”‚â”€â”€ ansible/ # Deployment automation (future)
â”‚â”€â”€ api/ # API service
â”‚â”€â”€ ci_cd/ # CI/CD configurations
â”‚â”€â”€ config/ # Configurations (settings.yaml)
â”‚â”€â”€ docker/ # Dockerfiles and docker-compose
â”‚â”€â”€ etl/ # Extract, Transform, Load scripts
â”‚â”€â”€ scripts/ # Utility scripts (log rotation, etc.)
â”‚â”€â”€ tests/ # Test cases
â”‚â”€â”€ .github/workflows/ # GitHub Actions CI/CD configs
â”‚â”€â”€ requirements.txt # Python dependencies
â”‚â”€â”€ docker-compose.yml # Multi-service orchestration
â”‚â”€â”€ README.md # Project documentation
```

---

## âš™ï¸ Setup & Installation

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/AppleShay/global-event-pipeline.git
cd global-event-pipeline
```

### 2ï¸âƒ£ Build & Run Containers

```bash
cd docker
docker compose build --no-cache
docker compose up
```

---

## â³ Scheduling with Cron

The ETL pipeline is scheduled to run weekly using a cron job:

```cron
0 9 * * 1 cd /mnt/b/DE/global-event-pipeline/docker && docker compose run etl
```

Logs are written to `/mnt/b/DE/global-event-pipeline/etl_weekly.log` and rotated automatically by the log rotation script.

---

## ğŸ›  Log Rotation

A custom log rotation script is included to prevent large log file sizes:

```bash
bash scripts/log_rotate.sh
```

This script automatically compresses and timestamps old logs when they exceed the configured size.

---

## ğŸ“¡ API Access

Once the pipeline runs, the API is available at:

```
http://localhost:8000/events
```

It serves stored event data from MongoDB.

---

## ğŸ”„ CI/CD Pipeline
CI: Runs tests and builds Docker images on every push.

CD: Pushes the Docker image to DockerHub automatically.

DockerHub Image:
```
docker pull appleshay/global-event-pipeline:latest
docker run appleshay/global-event-pipeline:latest
```

---
## ğŸ“Œ Future Enhancements
- Versioned releases on DockerHub (v1.0.0, v1.1.0, etc.)

- Automated cloud deployment (AWS, GCP, or Swedish Science Cloud)

- Enhanced data analytics on ingested events
---

**Author:** Shaheryar (AppleShay)
**Repository:** [Global Event Pipeline](https://github.com/AppleShay/global-event-pipeline)
